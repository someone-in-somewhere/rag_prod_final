"""
Document Ingestion Module
=========================
Module xá»­ lÃ½ viá»‡c Ä‘á»c, parse vÃ  chunking cÃ¡c tÃ i liá»‡u Ä‘á»ƒ Ä‘Æ°a vÃ o há»‡ thá»‘ng RAG.

CÃ¡c tÃ­nh nÄƒng chÃ­nh:
- Parse nhiá»u Ä‘á»‹nh dáº¡ng: PDF, DOCX, TXT, Images
- TrÃ­ch xuáº¥t text, báº£ng, hÃ¬nh áº£nh tá»« tÃ i liá»‡u
- Semantic Chunking: chia vÄƒn báº£n theo ngá»¯ nghÄ©a (giá»¯ nguyÃªn code blocks, báº£ng)
- OCR + Vision: trÃ­ch xuáº¥t vÃ  mÃ´ táº£ ná»™i dung hÃ¬nh áº£nh

Quy trÃ¬nh Ingest:
1. Kiá»ƒm tra giá»›i háº¡n file (kÃ­ch thÆ°á»›c, sá»‘ trang)
2. Parse tÃ i liá»‡u theo Ä‘á»‹nh dáº¡ng
3. TrÃ­ch xuáº¥t vÃ  xá»­ lÃ½ hÃ¬nh áº£nh (OCR + Vision)
4. Chunk vÄƒn báº£n theo semantic boundaries
5. Táº¡o metadata vÃ  tráº£ vá» chunks

Sá»­ dá»¥ng:
    from document_ingest import ingest_document
    result = ingest_document("path/to/document.pdf", use_semantic_chunking=True)
    # result = {"chunks": [...], "metadata": {...}, ...}
"""

import pymupdf
from docx import Document as DocxDocument
from docx.opc.constants import RELATIONSHIP_TYPE as RT
from pathlib import Path
from typing import List, Dict, Tuple
import hashlib
import os
import re
import tempfile
import uuid
import time
from datetime import datetime

from config import (
    CHUNK_SIZE, CHUNK_OVERLAP, UPLOAD_DIR,
    MAX_FILE_SIZE_MB, MAX_PDF_PAGES, MAX_IMAGE_SIZE_MB,
    DEBUG_CHUNKS, DEBUG_INGEST
)


def log_ingest(message: str):
    """
    Log vá»›i timestamp cho document ingestion.

    LuÃ´n hiá»ƒn thá»‹ (khÃ´ng phá»¥ thuá»™c DEBUG flag) vÃ¬ Ä‘Ã¢y lÃ  thÃ´ng tin
    quan trá»ng vá» tiáº¿n trÃ¬nh xá»­ lÃ½ tÃ i liá»‡u.

    Args:
        message: Ná»™i dung log
    """
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] ğŸ“„ {message}")


def log_chunk_debug(message: str):
    """
    Log debug cho chunking process.

    Chá»‰ hiá»ƒn thá»‹ khi DEBUG_CHUNKS=True trong config.

    Args:
        message: Ná»™i dung log debug
    """
    if DEBUG_CHUNKS:
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] ğŸ”ª CHUNK: {message}")

# Patterns Ä‘á»ƒ detect boundaries
CODE_BLOCK_PATTERN = re.compile(r'```[\s\S]*?```|`[^`]+`')
HEADING_PATTERN = re.compile(r'^#{1,6}\s+.+$|^[A-Z][^.!?]*:$|^\d+\.\d*\s+[A-Z]', re.MULTILINE)
TABLE_MARKER = re.compile(r'^\s*\|.*\|.*$|^\[Table|^\[Page.*Table', re.MULTILINE)
REGISTER_PATTERN = re.compile(r'Register\s+Description|Bit\s+Field|Address\s+Offset|0x[0-9A-Fa-f]+', re.IGNORECASE)


def compute_file_hash(filepath: str) -> str:
    """
    TÃ­nh MD5 hash cá»§a file Ä‘á»ƒ lÃ m document ID.

    Hash Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ:
    - Äá»‹nh danh duy nháº¥t cho má»—i tÃ i liá»‡u
    - PhÃ¡t hiá»‡n tÃ i liá»‡u trÃ¹ng láº·p
    - Theo dÃµi phiÃªn báº£n tÃ i liá»‡u

    Args:
        filepath: ÄÆ°á»ng dáº«n Ä‘áº¿n file

    Returns:
        str: MD5 hash dáº¡ng hex string (32 kÃ½ tá»±)

    Example:
        hash = compute_file_hash("document.pdf")
        # "a1b2c3d4e5f6..."
    """
    hasher = hashlib.md5()
    with open(filepath, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            hasher.update(chunk)
    return hasher.hexdigest()


def check_file_limits(filepath: str, max_size_mb: int = MAX_FILE_SIZE_MB) -> float:
    """
    Kiá»ƒm tra file cÃ³ vÆ°á»£t quÃ¡ giá»›i háº¡n kÃ­ch thÆ°á»›c khÃ´ng.

    Args:
        filepath: ÄÆ°á»ng dáº«n Ä‘áº¿n file
        max_size_mb: Giá»›i háº¡n kÃ­ch thÆ°á»›c tá»‘i Ä‘a (MB)

    Returns:
        float: KÃ­ch thÆ°á»›c file tÃ­nh báº±ng MB

    Raises:
        ValueError: Náº¿u file vÆ°á»£t quÃ¡ giá»›i háº¡n
    """
    file_size_mb = os.path.getsize(filepath) / (1024 * 1024)
    if file_size_mb > max_size_mb:
        raise ValueError(f"File quÃ¡ lá»›n: {file_size_mb:.1f}MB (giá»›i háº¡n {max_size_mb}MB)")
    return file_size_mb


def detect_segment_type(text: str) -> str:
    """
    PhÃ¡t hiá»‡n loáº¡i ná»™i dung cá»§a má»™t Ä‘oáº¡n vÄƒn báº£n.

    PhÃ¢n loáº¡i giÃºp chunking quyáº¿t Ä‘á»‹nh cÃ¡ch xá»­ lÃ½:
    - code: Giá»¯ nguyÃªn, khÃ´ng cáº¯t giá»¯a block
    - table: Giá»¯ nguyÃªn cáº¥u trÃºc báº£ng
    - register: MÃ´ táº£ thanh ghi, giá»¯ nguyÃªn
    - heading: TiÃªu Ä‘á», dÃ¹ng lÃ m Ä‘iá»ƒm báº¯t Ä‘áº§u chunk má»›i
    - text: VÄƒn báº£n thÆ°á»ng, cÃ³ thá»ƒ cáº¯t

    Args:
        text: Äoáº¡n vÄƒn báº£n cáº§n phÃ¢n loáº¡i

    Returns:
        str: Loáº¡i segment ("code", "table", "register", "heading", "text")
    """
    if CODE_BLOCK_PATTERN.search(text):
        return "code"
    if TABLE_MARKER.search(text):
        return "table"
    if REGISTER_PATTERN.search(text):
        return "register"
    if HEADING_PATTERN.match(text.strip()):
        return "heading"
    return "text"


def find_semantic_boundaries(text: str) -> List[Tuple[int, str]]:
    """
    TÃ¬m cÃ¡c Ä‘iá»ƒm boundary tá»± nhiÃªn trong vÄƒn báº£n.

    Semantic boundaries lÃ  cÃ¡c vá»‹ trÃ­ logic Ä‘á»ƒ chia vÄƒn báº£n:
    - Headings: TiÃªu Ä‘á» section/chapter
    - Code blocks: Báº¯t Ä‘áº§u vÃ  káº¿t thÃºc code
    - Tables: Báº¯t Ä‘áº§u báº£ng
    - Register descriptions: MÃ´ táº£ thanh ghi
    - Paragraph breaks: Ngáº¯t Ä‘oáº¡n (2 newlines)

    Args:
        text: VÄƒn báº£n cáº§n phÃ¢n tÃ­ch

    Returns:
        List[Tuple[int, str]]: Danh sÃ¡ch (vá»‹_trÃ­, loáº¡i_boundary)
        Ä‘Æ°á»£c sáº¯p xáº¿p theo vá»‹ trÃ­ tÄƒng dáº§n

    Example:
        boundaries = find_semantic_boundaries(text)
        # [(0, "start"), (150, "heading"), (300, "code_start"), ...]
    """
    boundaries = [(0, "start")]
    
    # TÃ¬m headings
    for match in HEADING_PATTERN.finditer(text):
        boundaries.append((match.start(), "heading"))
    
    # TÃ¬m code blocks
    for match in CODE_BLOCK_PATTERN.finditer(text):
        boundaries.append((match.start(), "code_start"))
        boundaries.append((match.end(), "code_end"))
    
    # TÃ¬m table markers
    for match in TABLE_MARKER.finditer(text):
        boundaries.append((match.start(), "table"))
    
    # TÃ¬m register sections
    for match in REGISTER_PATTERN.finditer(text):
        boundaries.append((match.start(), "register"))
    
    # TÃ¬m paragraph breaks (double newline)
    for match in re.finditer(r'\n\s*\n', text):
        boundaries.append((match.start(), "paragraph"))
    
    # Sort theo position
    boundaries.sort(key=lambda x: x[0])
    
    return boundaries


def semantic_chunk_text(
    text: str,
    chunk_size: int = CHUNK_SIZE,
    overlap: int = CHUNK_OVERLAP
) -> List[Dict]:
    """
    Chunk vÄƒn báº£n theo semantic boundaries.

    KhÃ¡c vá»›i simple chunking (cáº¯t theo sá»‘ tá»«), semantic chunking
    tÃ´n trá»ng cáº¥u trÃºc ngá»¯ nghÄ©a cá»§a vÄƒn báº£n:
    - Code blocks Ä‘Æ°á»£c giá»¯ nguyÃªn trong 1 chunk
    - Báº£ng khÃ´ng bá»‹ cáº¯t giá»¯a chá»«ng
    - Register descriptions Ä‘Æ°á»£c giá»¯ nguyÃªn
    - Heading luÃ´n báº¯t Ä‘áº§u chunk má»›i

    Quy trÃ¬nh:
    1. TÃ¬m táº¥t cáº£ semantic boundaries
    2. Chia text thÃ nh segments theo boundaries
    3. Merge segments thÃ nh chunks sao cho:
       - KhÃ´ng vÆ°á»£t quÃ¡ chunk_size
       - Code/table/register Ä‘á»§ lá»›n thÃ nh chunk riÃªng
       - CÃ³ overlap giá»¯a cÃ¡c chunks

    Args:
        text: VÄƒn báº£n cáº§n chunk
        chunk_size: Sá»‘ tá»« tá»‘i Ä‘a má»—i chunk (máº·c Ä‘á»‹nh tá»« config)
        overlap: Sá»‘ tá»« overlap giá»¯a chunks (máº·c Ä‘á»‹nh tá»« config)

    Returns:
        List[Dict]: Danh sÃ¡ch chunks, má»—i chunk cÃ³:
        - text: Ná»™i dung chunk
        - types: Danh sÃ¡ch loáº¡i content trong chunk
    """
    if not text.strip():
        return []

    log_chunk_debug(f"Input: {len(text)} chars, chunk_size={chunk_size}, overlap={overlap}")

    boundaries = find_semantic_boundaries(text)
    log_chunk_debug(f"Found {len(boundaries)} boundaries")

    chunks = []
    
    # Táº¡o segments tá»« boundaries
    segments = []
    for i in range(len(boundaries)):
        start = boundaries[i][0]
        end = boundaries[i + 1][0] if i + 1 < len(boundaries) else len(text)
        segment_text = text[start:end].strip()
        
        if segment_text:
            segment_type = detect_segment_type(segment_text)
            segments.append({
                "text": segment_text,
                "type": segment_type,
                "start": start,
                "end": end
            })
    
    # Merge segments thÃ nh chunks
    current_chunk = ""
    current_types = set()
    current_word_count = 0
    
    for seg in segments:
        seg_words = len(seg["text"].split())
        seg_type = seg["type"]
        
        # Náº¿u segment lÃ  code/table/register vÃ  Ä‘á»§ lá»›n -> chunk riÃªng
        if seg_type in ["code", "table", "register"] and seg_words > 50:
            # Save current chunk trÆ°á»›c
            if current_chunk.strip():
                chunks.append({
                    "text": current_chunk.strip(),
                    "types": list(current_types)
                })
            
            # Segment nÃ y thÃ nh chunk riÃªng
            chunks.append({
                "text": seg["text"],
                "types": [seg_type]
            })
            
            current_chunk = ""
            current_types = set()
            current_word_count = 0
            continue
        
        # Náº¿u thÃªm segment nÃ y vÆ°á»£t quÃ¡ chunk_size
        if current_word_count + seg_words > chunk_size:
            # Save current chunk
            if current_chunk.strip():
                chunks.append({
                    "text": current_chunk.strip(),
                    "types": list(current_types)
                })
            
            # Overlap: láº¥y pháº§n cuá»‘i cá»§a chunk cÅ©
            if overlap > 0 and current_chunk:
                words = current_chunk.split()
                overlap_text = " ".join(words[-overlap:]) + "\n\n"
                current_chunk = overlap_text
                current_word_count = overlap
            else:
                current_chunk = ""
                current_word_count = 0
            
            current_types = set()
        
        # ThÃªm segment vÃ o current chunk
        current_chunk += seg["text"] + "\n\n"
        current_types.add(seg_type)
        current_word_count += seg_words
    
    # Save chunk cuá»‘i
    if current_chunk.strip():
        chunks.append({
            "text": current_chunk.strip(),
            "types": list(current_types)
        })
    
    return chunks


def chunk_text(
    text: str, 
    chunk_size: int = CHUNK_SIZE, 
    overlap: int = CHUNK_OVERLAP,
    use_semantic: bool = True
) -> List[str]:
    """
    Wrapper function - tráº£ vá» list strings Ä‘á»ƒ compatible vá»›i code cÅ©.
    """
    if use_semantic:
        chunks = semantic_chunk_text(text, chunk_size, overlap)
        return [c["text"] for c in chunks]
    
    # Fallback: simple word-based chunking
    if not text.strip():
        return []
    
    words = text.split()
    chunks = []
    start = 0
    
    while start < len(words):
        end = start + chunk_size
        chunk = " ".join(words[start:end])
        if chunk.strip():
            chunks.append(chunk)
        start = end - overlap
        if start < 0:
            start = 0
        if end >= len(words):
            break
    
    return chunks


def format_table(table_data: List[List]) -> str:
    """Format table data thÃ nh text"""
    if not table_data:
        return ""
    
    lines = []
    for row in table_data:
        cells = [str(cell).strip() if cell else "" for cell in row]
        lines.append(" | ".join(cells))
    return "\n".join(lines)


def parse_pdf(filepath: str, max_pages: int = MAX_PDF_PAGES) -> Dict:
    """Parse PDF: text + tables + images"""
    start_time = time.time()
    file_size_mb = check_file_limits(filepath)

    doc = pymupdf.open(filepath)
    page_count = len(doc)

    if page_count > max_pages:
        doc.close()
        raise ValueError(f"PDF quÃ¡ nhiá»u trang: {page_count} (giá»›i háº¡n {max_pages} trang)")

    log_ingest(f"PDF: {page_count} trang, {file_size_mb:.1f}MB")

    all_text = []
    tables_text = []
    image_count = 0

    # Count images first
    for page in doc:
        image_count += len(page.get_images())

    log_ingest(f"TÃ¬m tháº¥y: {page_count} trang, {image_count} áº£nh")

    for page_num, page in enumerate(doc):
        # Extract text
        text = page.get_text("text")
        if text.strip():
            all_text.append(f"[Page {page_num + 1}]\n{text}")

        # Extract tables
        try:
            tabs = page.find_tables()
            for i, tab in enumerate(tabs):
                table_data = tab.extract()
                if table_data:
                    table_str = format_table(table_data)
                    tables_text.append(f"[Page {page_num + 1} - Table {i + 1}]\n{table_str}")
        except Exception as e:
            print(f"Warning: Could not extract tables from page {page_num + 1}: {e}")

    # Extract images
    images_text = []
    if image_count > 0:
        log_ingest(f"Äang xá»­ lÃ½ {image_count} áº£nh (OCR + Vision)...")
        image_start = time.time()
        images_text = extract_images_from_pdf(doc, filepath)
        image_elapsed = time.time() - image_start
        log_ingest(f"Xá»­ lÃ½ áº£nh hoÃ n táº¥t: {len(images_text)}/{image_count} áº£nh - {image_elapsed:.2f}s")

    doc.close()

    combined = "\n\n".join(all_text)
    if tables_text:
        combined += "\n\n[TABLES]\n" + "\n\n".join(tables_text)
    if images_text:
        combined += "\n\n[IMAGES]\n" + "\n\n".join(images_text)

    elapsed = time.time() - start_time
    log_ingest(f"PDF parsed: {page_count} trang, {len(tables_text)} báº£ng, {len(images_text)} áº£nh - {elapsed:.2f}s")

    return {
        "text": combined,
        "page_count": page_count,
        "table_count": len(tables_text),
        "image_count": len(images_text),
        "file_size_mb": file_size_mb,
        "has_tables": len(tables_text) > 0,
        "has_images": len(images_text) > 0,
        "parse_time_s": elapsed
    }


def extract_images_from_pdf(doc, filepath: str) -> List[str]:
    """Extract vÃ  xá»­ lÃ½ images tá»« PDF file"""
    from ocr_utils import process_image

    images_text = []
    temp_dir = tempfile.mkdtemp()
    processed_xrefs = set()  # TrÃ¡nh xá»­ lÃ½ áº£nh trÃ¹ng

    try:
        img_idx = 0
        for page_num, page in enumerate(doc):
            image_list = page.get_images()

            for img in image_list:
                xref = img[0]

                # Skip náº¿u Ä‘Ã£ xá»­ lÃ½ áº£nh nÃ y (áº£nh cÃ³ thá»ƒ xuáº¥t hiá»‡n nhiá»u trang)
                if xref in processed_xrefs:
                    continue
                processed_xrefs.add(xref)

                try:
                    # Extract image
                    base_image = doc.extract_image(xref)
                    image_data = base_image["image"]
                    image_ext = base_image["ext"]

                    # Check image size
                    image_size_mb = len(image_data) / (1024 * 1024)
                    if image_size_mb > MAX_IMAGE_SIZE_MB:
                        print(f"Skipping image {img_idx}: too large ({image_size_mb:.1f}MB)")
                        continue

                    # Skip very small images (likely icons/bullets)
                    if len(image_data) < 5000:  # < 5KB
                        continue

                    # Save temp image file
                    temp_image_path = os.path.join(temp_dir, f"image_{img_idx}.{image_ext}")
                    with open(temp_image_path, "wb") as f:
                        f.write(image_data)

                    # Process image with OCR and Vision
                    result = process_image(temp_image_path)

                    if result["combined"] and "[No content extracted" not in result["combined"]:
                        images_text.append(f"[Page {page_num + 1} - Image {img_idx + 1}]\n{result['combined']}")
                        img_idx += 1

                except Exception as e:
                    print(f"Error processing image {img_idx} in PDF: {e}")
                    continue

    finally:
        # Cleanup temp files
        import shutil
        try:
            shutil.rmtree(temp_dir)
        except Exception as e:
            print(f"Warning: Could not cleanup temp dir: {e}")

    return images_text


def count_docx_pages(filepath: str) -> int:
    """
    Æ¯á»›c tÃ­nh sá»‘ trang cá»§a DOCX.
    DOCX khÃ´ng cÃ³ concept "page" cá»‘ Ä‘á»‹nh nhÆ° PDF, 
    nÃªn Æ°á»›c tÃ­nh dá»±a trÃªn sá»‘ tá»« (~300 tá»«/trang) vÃ  sá»‘ áº£nh/báº£ng.
    """
    doc = DocxDocument(filepath)
    
    # Äáº¿m tá»•ng sá»‘ tá»«
    total_words = 0
    for para in doc.paragraphs:
        total_words += len(para.text.split())
    
    # Äáº¿m sá»‘ báº£ng (má»—i báº£ng ~0.5 trang)
    table_count = len(doc.tables)
    
    # Äáº¿m sá»‘ áº£nh (má»—i áº£nh ~0.3 trang)
    image_count = 0
    for rel in doc.part.rels.values():
        if "image" in rel.reltype:
            image_count += 1
    
    # Æ¯á»›c tÃ­nh: 300 tá»«/trang + báº£ng + áº£nh
    estimated_pages = (total_words / 300) + (table_count * 0.5) + (image_count * 0.3)
    
    return max(1, int(estimated_pages))


def parse_docx(filepath: str, max_pages: int = MAX_PDF_PAGES) -> Dict:
    """Parse DOCX: text + tables + images"""
    start_time = time.time()
    file_size_mb = check_file_limits(filepath)

    # Æ¯á»›c tÃ­nh sá»‘ trang vÃ  kiá»ƒm tra giá»›i háº¡n
    estimated_pages = count_docx_pages(filepath)
    if estimated_pages > max_pages:
        raise ValueError(
            f"DOCX quÃ¡ dÃ i: Æ°á»›c tÃ­nh ~{estimated_pages} trang (giá»›i háº¡n {max_pages} trang). "
            f"Vui lÃ²ng chia nhá» tÃ i liá»‡u."
        )

    log_ingest(f"DOCX: ~{estimated_pages} trang (Æ°á»›c tÃ­nh), {file_size_mb:.1f}MB")

    doc = DocxDocument(filepath)
    paragraphs = []
    tables_text = []
    images_text = []

    # Extract paragraphs
    for para in doc.paragraphs:
        if para.text.strip():
            # Detect heading style
            if para.style and para.style.name.startswith('Heading'):
                paragraphs.append(f"## {para.text}")
            else:
                paragraphs.append(para.text)

    # Extract tables
    for i, table in enumerate(doc.tables):
        table_data = []
        for row in table.rows:
            row_data = [cell.text.strip() for cell in row.cells]
            table_data.append(row_data)
        if table_data:
            table_str = format_table(table_data)
            tables_text.append(f"[Table {i + 1}]\n{table_str}")

    # Count images before extraction
    image_count = 0
    for rel in doc.part.rels.values():
        if "image" in rel.reltype:
            image_count += 1

    log_ingest(f"TÃ¬m tháº¥y: {len(paragraphs)} Ä‘oáº¡n vÄƒn, {len(tables_text)} báº£ng, {image_count} áº£nh")

    # Extract images (cÃ³ thá»ƒ máº¥t thá»i gian)
    if image_count > 0:
        log_ingest(f"Äang xá»­ lÃ½ {image_count} áº£nh (OCR + Vision)...")
        image_start = time.time()
        images_text = extract_images_from_docx(doc, filepath)
        image_elapsed = time.time() - image_start
        log_ingest(f"Xá»­ lÃ½ áº£nh hoÃ n táº¥t: {len(images_text)}/{image_count} áº£nh - {image_elapsed:.2f}s")

    # Combine all content
    combined = "\n\n".join(paragraphs)
    if tables_text:
        combined += "\n\n[TABLES]\n" + "\n\n".join(tables_text)
    if images_text:
        combined += "\n\n[IMAGES]\n" + "\n\n".join(images_text)

    elapsed = time.time() - start_time
    log_ingest(f"DOCX parsed: ~{estimated_pages} trang, {len(tables_text)} báº£ng, {len(images_text)} áº£nh - {elapsed:.2f}s")

    return {
        "text": combined,
        "page_count": estimated_pages,
        "paragraph_count": len(paragraphs),
        "table_count": len(tables_text),
        "image_count": len(images_text),
        "file_size_mb": file_size_mb,
        "has_tables": len(tables_text) > 0,
        "has_images": len(images_text) > 0,
        "parse_time_s": elapsed
    }


def extract_images_from_docx(doc: DocxDocument, filepath: str) -> List[str]:
    """Extract vÃ  xá»­ lÃ½ images tá»« DOCX file"""
    from ocr_utils import process_image
    
    images_text = []
    temp_dir = tempfile.mkdtemp()
    
    try:
        # Láº¥y táº¥t cáº£ image relationships tá»« document
        image_parts = []
        
        # Check main document rels
        for rel in doc.part.rels.values():
            if "image" in rel.reltype:
                image_parts.append(rel.target_part)
        
        if not image_parts:
            return []
        
        print(f"Found {len(image_parts)} images in DOCX")
        
        for idx, image_part in enumerate(image_parts):
            try:
                # Get image data
                image_data = image_part.blob
                
                # Determine extension from content type
                content_type = image_part.content_type
                if "png" in content_type:
                    ext = ".png"
                elif "jpeg" in content_type or "jpg" in content_type:
                    ext = ".jpg"
                elif "gif" in content_type:
                    ext = ".gif"
                elif "bmp" in content_type:
                    ext = ".bmp"
                else:
                    ext = ".png"  # Default
                
                # Save temp image file
                temp_image_path = os.path.join(temp_dir, f"image_{idx}{ext}")
                with open(temp_image_path, "wb") as f:
                    f.write(image_data)
                
                # Check image size
                image_size_mb = len(image_data) / (1024 * 1024)
                if image_size_mb > MAX_IMAGE_SIZE_MB:
                    print(f"Skipping image {idx}: too large ({image_size_mb:.1f}MB)")
                    continue
                
                # Process image with OCR and Vision
                result = process_image(temp_image_path)
                
                if result["combined"] and "[No content extracted" not in result["combined"]:
                    images_text.append(f"[Image {idx + 1}]\n{result['combined']}")
                
            except Exception as e:
                print(f"Error processing image {idx} in DOCX: {e}")
                continue
    
    finally:
        # Cleanup temp files
        import shutil
        try:
            shutil.rmtree(temp_dir)
        except Exception as e:
            print(f"Warning: Could not cleanup temp dir: {e}")
    
    return images_text


def parse_txt(filepath: str) -> Dict:
    """Parse plain text file"""
    file_size_mb = check_file_limits(filepath)
    
    with open(filepath, "r", encoding="utf-8", errors="ignore") as f:
        text = f.read()
    return {
        "text": text,
        "file_size_mb": file_size_mb
    }


def parse_image(filepath: str) -> Dict:
    """Parse image: OCR + Vision caption"""
    from ocr_utils import process_image
    
    file_size_mb = check_file_limits(filepath, max_size_mb=MAX_IMAGE_SIZE_MB)
    
    result = process_image(filepath)
    return {
        "text": result["combined"],
        "ocr_text": result["ocr_text"],
        "caption": result["caption"],
        "file_size_mb": file_size_mb
    }


def ingest_document(filepath: str, use_semantic_chunking: bool = True) -> Dict:
    """
    Ingest má»™t document vÃ  tráº£ vá» chunks + metadata
    """
    total_start = time.time()
    path = Path(filepath)
    ext = path.suffix.lower()
    filename = path.name

    log_ingest(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    log_ingest(f"Báº®T Äáº¦U INGEST: {filename}")
    log_ingest(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    # Parse theo loáº¡i file
    if ext == ".pdf":
        parsed = parse_pdf(filepath)
        doc_type = "pdf"
    elif ext == ".docx":
        parsed = parse_docx(filepath)
        doc_type = "docx"
    elif ext == ".txt":
        parsed = parse_txt(filepath)
        doc_type = "txt"
    elif ext in [".jpg", ".jpeg", ".png"]:
        parsed = parse_image(filepath)
        doc_type = "image"
    else:
        raise ValueError(f"Unsupported file type: {ext}")
    
    # Chunk text
    log_ingest(f"Äang táº¡o chunks (semantic={use_semantic_chunking})...")
    chunk_start = time.time()
    raw_text = parsed.get("text", "")
    chunks = chunk_text(raw_text, use_semantic=use_semantic_chunking)
    chunk_elapsed = time.time() - chunk_start

    log_ingest(f"Táº¡o xong {len(chunks)} chunks - {chunk_elapsed:.2f}s")

    # Táº¡o metadata
    file_hash = compute_file_hash(filepath)
    base_metadata = {
        "source": filename,
        "file_hash": file_hash,
        "doc_type": doc_type,
        "ingested_at": datetime.now().isoformat(),
        "chunking": "semantic" if use_semantic_chunking else "simple"
    }

    # Táº¡o chunk documents
    chunk_docs = []
    for i, chunk in enumerate(chunks):
        chunk_docs.append({
            "text": chunk,
            "metadata": {
                **base_metadata,
                "chunk_index": i,
                "total_chunks": len(chunks)
            }
        })

    total_elapsed = time.time() - total_start

    # Log tá»•ng káº¿t
    log_ingest(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    log_ingest(f"HOÃ€N Táº¤T INGEST: {filename}")
    log_ingest(f"  â€¢ Loáº¡i file: {doc_type.upper()}")
    log_ingest(f"  â€¢ KÃ­ch thÆ°á»›c: {parsed.get('file_size_mb', 0):.1f}MB")
    if 'page_count' in parsed:
        log_ingest(f"  â€¢ Sá»‘ trang: {parsed.get('page_count', 0)}")
    if 'table_count' in parsed:
        log_ingest(f"  â€¢ Sá»‘ báº£ng: {parsed.get('table_count', 0)}")
    if 'image_count' in parsed:
        log_ingest(f"  â€¢ Sá»‘ áº£nh: {parsed.get('image_count', 0)}")
    log_ingest(f"  â€¢ Sá»‘ chunks: {len(chunks)}")
    log_ingest(f"  â€¢ Tá»•ng thá»i gian: {total_elapsed:.2f}s")
    log_ingest(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

    return {
        "doc_id": file_hash,
        "filename": filename,
        "doc_type": doc_type,
        "raw_text": raw_text,
        "chunks": chunk_docs,
        "chunk_count": len(chunks),
        "metadata": base_metadata,
        "stats": {
            "page_count": parsed.get("page_count", 0),
            "table_count": parsed.get("table_count", 0),
            "image_count": parsed.get("image_count", 0),
            "file_size_mb": parsed.get("file_size_mb", 0),
            "total_time_s": total_elapsed
        }
    }